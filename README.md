Prism
=======
![alt tag](/images/hand_detection_sample.jpg)
Prism is an open source augmented reality system. It snaps magnetically to glasses frames, and takes input primarily by hand gestures. It's purpose is not only limited to our vision, but anyones programming in any language. The API uses a shell script outputting in JSON (tentative), which makes it easy for any language to reference it. The script provides the location of a hand, number of fingers, gestures that have been made, face detection, words heard (IRL subtitles project) and more. Hardware is made from scratch primarily as a learning opportunity, but also because it is difficult to find a linux board that fits the necessary form factor. This project is hugely abitious, and there are plenty of helpful areas to be worked on. Anyone interested in the project can email me at imcnanie.saga@gmail.com.

Prism Subtitles Project
=======
The Prism Subtitles Project is an accessibility feature for Prism that will allow a deaf user to see subtitles in their vision based on words spoken in the environment. When partnered with face detection, Subtitles will appear based on input from a microphone pointed at the person the user is speaking with. If no face is detected, words will be picked up from the environment.
